{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bf0f3f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This project is aimed to use a statistical model to predict the wind stress anomalies by sea surface temperature anomalies (SSTA). The relationship can be represented as $\\boldsymbol{\\tau_s} = \\boldsymbol{C} \\boldsymbol{T}$, where $\\boldsymbol{\\tau_s}$ and $\\boldsymbol{T}$ are state vectors of wind stress anomolies and SSTA, respectively, and $\\boldsymbol{C}$ is a constant coefficient (a matrix). Our goal is to derive $\\boldsymbol{C}$ using Singular Value Decomposition (SVD) analysis on a training dataset, and apply the relationship on a testing dataset.\n",
    "\n",
    "This project is going to:\n",
    "\n",
    "1. Formulate a statistical atmosphere model for predicting surface wind stress anomalies for given SST anomalies;\n",
    "2. Validate the simulated surface wind stress anomalies against observations;\n",
    "3. Perform sensitivity tests to see how the results depend on the number of SVDs used to compute the anomalies;\n",
    "4. Discuss whether the results make physical sense and why;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914fae0-a093-4004-a65b-b8ee13e07202",
   "metadata": {},
   "source": [
    "# Dataset and Method\n",
    "Surface temperature ($T_s$), zonal wind stress ($u$), meridional wind stress ($v$), and a land mask dataset are given. $T_s, u, v$ are three-dimensional, with two space dimensions and one time dimension. Datasets are divided into two parts: data in 1948-1999 are used as training dataset, and data in 2000-2017 are used as testing dataset.\n",
    "\n",
    "We follow the below steps to perform the SVD analysis:\n",
    "\n",
    "1. Normalize all the anomaly fields by dividing each of variables by its own standard deviation;\n",
    "2. Form a state vector for SSTA ($\\boldsymbol{T}$), and another one for zonal and meridional wind stress anomaly ($\\boldsymbol{\\tau_s}$). Note that $\\boldsymbol{\\tau_s}$ contains both wind stress component and has larger dimension than $\\boldsymbol{T}$;\n",
    "3. Form a normalized covariance matrix, $\\boldsymbol{A=\\tau _s T'}$, whose dimension should be $M\\times N$, where $M$ is the length for $\\boldsymbol{\\tau_s}$ and $N$ is length for $\\boldsymbol{T}$;\n",
    "4. Apply SVD on $\\boldsymbol{A}$ by calling Matlabâ€™s SVD function, which results in $\\boldsymbol{A=USV'}$, $S$ is a diagonal matrix with diagonal elements representing singular values - explained squared covariance in each SVD, $\\boldsymbol{U}$ contains all wind stress singular vectors and $V$ contains all SST singular vectors, which are self-orthogonal, i.e., $\\boldsymbol{VV'=I}$ and $\\boldsymbol{UU'=I}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654ef7a-096f-4f9f-86e1-9cd3daa445a5",
   "metadata": {},
   "source": [
    "# Results\n",
    "## SVD analysis\n",
    "Although the SVD MATLAB scripts are provided, I rewrite them in Python in order to better understand the SVD method. The Python script is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd93cf46-39a6-4bc1-b70b-f9a30ee74352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# read in the data\n",
    "dir = \"./NECP_monthly_mean_data/\"\n",
    "taux_ds = xr.open_dataset(dir + \"uflx.sfc.mon.mean.tropics.nc\", use_cftime=True)\n",
    "tauy_ds = xr.open_dataset(dir + \"vflx.sfc.mon.mean.tropics.nc\", use_cftime=True)\n",
    "sst_ds = xr.open_dataset(dir + \"skt.sfc.mon.mean.tropics.nc\", use_cftime=True)\n",
    "grid_ds = xr.open_dataset(dir + \"lsmask.tropics.nc\", use_cftime=True)\n",
    "# get the data\n",
    "taux, tauy, sst, grid = taux_ds.uflx, tauy_ds.vflx, sst_ds.skt, grid_ds.lsmask\n",
    "# reverse the latitude dimension to make it increasing\n",
    "taux = taux.reindex(lat=taux.lat[::-1])\n",
    "tauy = tauy.reindex(lat=tauy.lat[::-1])\n",
    "sst = sst.reindex(lat=sst.lat[::-1])\n",
    "grid = grid.reindex(lat=grid.lat[::-1])\n",
    "# select data from 1948 to 1999 for training, \n",
    "# and in a target region (30N-30S, 100E-60W)\n",
    "lat_min, lat_max = -30, 30\n",
    "lon_min, lon_max = 100, 300\n",
    "taux = taux.sel(time=slice(\"1948\", \"1999\"), lon=slice(lon_min, lon_max))\n",
    "tauy = tauy.sel(time=slice(\"1948\", \"1999\"), lon=slice(lon_min, lon_max))\n",
    "sst = sst.sel(time=slice(\"1948\", \"1999\"), lon=slice(lon_min, lon_max))\n",
    "grid = grid.sel(lon=slice(lon_min, lon_max))\n",
    "# get the data as numpy arrays\n",
    "taux, tauy, sst, grid = taux.values, tauy.values, sst.values, grid.values\n",
    "grid = grid[0,:,:]\n",
    "# get dimensions\n",
    "nt, ny, nx = taux.shape\n",
    "# reshape the time dimension to nmonths x nyears\n",
    "taux = taux.reshape(nt//12, 12, ny, nx)\n",
    "tauy = tauy.reshape(nt//12, 12, ny, nx)\n",
    "sst = sst.reshape(nt//12, 12, ny, nx)\n",
    "# get seasonal means\n",
    "taux_mean = taux.mean(axis=0, keepdims=True)\n",
    "tauy_mean = tauy.mean(axis=0, keepdims=True)\n",
    "sst_mean = sst.mean(axis=0, keepdims=True)\n",
    "# remove seasonal cycle\n",
    "taux_anom = taux - taux_mean\n",
    "tauy_anom = tauy - tauy_mean\n",
    "sst_anom = sst - sst_mean\n",
    "# reshape time to 1D\n",
    "taux_anom = taux_anom.reshape(nt, ny, nx)\n",
    "tauy_anom = tauy_anom.reshape(nt, ny, nx)\n",
    "sst_anom = sst_anom.reshape(nt, ny, nx)\n",
    "# normalize the data by the standard deviation\n",
    "taux_anom /= taux_anom.std()\n",
    "tauy_anom /= tauy_anom.std()\n",
    "sst_anom /= sst_anom.std()\n",
    "# mask out the land\n",
    "taux_anom[:, grid == -1] = 0\n",
    "tauy_anom[:, grid == -1] = 0\n",
    "sst_anom[:, grid == -1] = 0\n",
    "# concatenate taux and tauy\n",
    "tau = np.concatenate((taux_anom, tauy_anom), axis=1)\n",
    "# reshape vars to space x time\n",
    "tau = tau.reshape(nt, 2*ny*nx).T \n",
    "sst = sst_anom.reshape(nt, ny*nx).T\n",
    "# form matrix A\n",
    "A = 1/nt * tau @ sst.T\n",
    "# apply SVD on A\n",
    "U, S, V = la.svd(A, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be5c3877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6848, 6848) (3424,) (3424, 3424)\n",
      "[0.7359658  0.08932026 0.06563405 0.02477056 0.0167234  0.01135552\n",
      " 0.00955939 0.00791305 0.00536468 0.00463725]\n"
     ]
    }
   ],
   "source": [
    "print(U.shape, S.shape, V.shape)\n",
    "n_modes = 10\n",
    "# get the explained variance\n",
    "var = S**2\n",
    "var /= var.sum()\n",
    "# get the first n_modes modes\n",
    "U = U[:, :n_modes]\n",
    "S = S[:n_modes]\n",
    "V = V[:n_modes, :]\n",
    "var = var[:n_modes]\n",
    "# get the spatial patterns\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jinjun Liu"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "title": "ATMO 615 Midterm Project",
  "vscode": {
   "interpreter": {
    "hash": "89830f9ad87ab3f8382f138353d764f6fd4f3929eb31315f2489d4f42e4797e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
